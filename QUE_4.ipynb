{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37847bde",
   "metadata": {},
   "source": [
    "# Readme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511892d8",
   "metadata": {},
   "source": [
    "### 利用que_3中的数据处理和特征化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca1dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PassengerId HomePlanet CryoSleep  Cabin  Destination   Age    VIP  \\\n",
      "0     0001_01     Europa     False  B/0/P  TRAPPIST-1e  39.0  False   \n",
      "1     0002_01      Earth     False  F/0/S  TRAPPIST-1e  24.0  False   \n",
      "2     0003_01     Europa     False  A/0/S  TRAPPIST-1e  58.0   True   \n",
      "3     0003_02     Europa     False  A/0/S  TRAPPIST-1e  33.0  False   \n",
      "4     0004_01      Earth     False  F/1/S  TRAPPIST-1e  16.0  False   \n",
      "\n",
      "   RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
      "0          0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
      "1        109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
      "2         43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
      "3          0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
      "4        303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
      "\n",
      "   Transported  \n",
      "0        False  \n",
      "1         True  \n",
      "2        False  \n",
      "3        False  \n",
      "4         True  \n",
      "训练集形状: (8545, 14)\n",
      "测试集形状: (148, 14)\n",
      "\n",
      "特征列名: \n",
      " ['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Name', 'Transported']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8545 entries, 0 to 8544\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8545 non-null   object \n",
      " 1   HomePlanet    8348 non-null   object \n",
      " 2   CryoSleep     8335 non-null   object \n",
      " 3   Cabin         8347 non-null   object \n",
      " 4   Destination   8367 non-null   object \n",
      " 5   Age           8367 non-null   float64\n",
      " 6   VIP           8344 non-null   object \n",
      " 7   RoomService   8365 non-null   float64\n",
      " 8   FoodCourt     8363 non-null   float64\n",
      " 9   ShoppingMall  8344 non-null   float64\n",
      " 10  Spa           8367 non-null   float64\n",
      " 11  VRDeck        8360 non-null   float64\n",
      " 12  Name          8352 non-null   object \n",
      " 13  Transported   8545 non-null   bool   \n",
      "dtypes: bool(1), float64(6), object(7)\n",
      "memory usage: 876.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取训练集和测试集\n",
    "train_df = pd.read_csv('./data4_3/train.csv')  \n",
    "test_df = pd.read_csv('./data4_3/test.csv')\n",
    "\n",
    "print(train_df.head())\n",
    "# print(train_df.tail())\n",
    "\n",
    "print(f\"训练集形状: {train_df.shape}\")  #\n",
    "print(f\"测试集形状: {test_df.shape}\\n\")  #\n",
    "\n",
    "print(\"特征列名: \\n\", train_df.columns.tolist()) #\n",
    "\n",
    "print(train_df.info())  # info方法查看类型和缺失值\n",
    "#print(test_df.info())\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "num_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in num_cols:\n",
    "    for i in range(len(train_df[col])):\n",
    "        if train_df[col][i] > 4*train_df[col].std():\n",
    "            train_df[col][i] = train_df[col].mean()\n",
    "\n",
    "train_df[['Cabin_Deck', 'Cabin_Number', 'Cabin_Side']] = train_df['Cabin'].str.split('/', expand=True)\n",
    "test_df[['Cabin_Deck', 'Cabin_Number', 'Cabin_Side']] = test_df['Cabin'].str.split('/', expand=True)\n",
    "\n",
    "print(train_df.isnull().sum())\n",
    "# 对数值列（如 gpa、gmat、work_exp）进行统计描述\n",
    "print(train_df.describe())  # 包含均值、标准差、最小值、最大值、分位数等\n",
    "\n",
    "non_num_cols = train_df.select_dtypes(include=['object'])\n",
    "\n",
    "print(non_num_cols.count())\n",
    "non_num_cols = non_num_cols.columns.tolist()\n",
    "\n",
    "for col in non_num_cols:\n",
    "    print(f\"===== 特征：{col} =====\")\n",
    "    \n",
    "    # 获取唯一类别（含缺失值可保留）\n",
    "    unique_categories = train_df[col].unique()\n",
    "    print(f\"唯一类别（共{len(unique_categories)}种）：{unique_categories}\")\n",
    "\n",
    "    # 获取每个类别的出现次数排除缺失值，按降序排序\n",
    "    value_counts = train_df[col].value_counts(dropna=False)  # dropna=False  包含缺失值\n",
    "    print(\"类别出现次数：\")\n",
    "    print(value_counts)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")  \n",
    "\n",
    "# 按逻辑填补缺失值\n",
    "# ['PassengerId', 'HomePlanet', 'CryoSleep', 'Cabin', 'Destination', 'Age', 'VIP', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck', 'Name', 'Transported']\n",
    "train_df['HomePlanet'] = train_df['HomePlanet'].fillna(train_df['HomePlanet'].mode()[0])#填众数\n",
    "train_df['CryoSleep'] = train_df['CryoSleep'].fillna(train_df['CryoSleep'].mode()[0])#填众数\n",
    "train_df['Cabin_Deck'] = train_df['Cabin_Deck'].fillna(train_df['Cabin_Deck'].mode()[0])#填众数\n",
    "train_df['Cabin_Number'] = train_df['Cabin_Number'].str[1].fillna(train_df['Cabin_Number'].mode()[0])#填众数\n",
    "train_df['Cabin_Side'] = train_df['Cabin_Side'].str[2].fillna(train_df['Cabin_Side'].mode()[0])#填众数\n",
    "train_df['Destination'] = train_df['Destination'].fillna(train_df['Destination'].mode()[0])\n",
    "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())#填中位数\n",
    "train_df['VIP'] = train_df['VIP'].fillna(train_df['VIP'].mode()[0])#填众数\n",
    "train_df['RoomService'] = train_df['RoomService'].fillna(train_df['RoomService'].mean())#平均\n",
    "train_df['FoodCourt'] = train_df['FoodCourt'].fillna(train_df['FoodCourt'].mean())#平均\n",
    "train_df['ShoppingMall'] = train_df['ShoppingMall'].fillna(train_df['ShoppingMall'].mean())#平均\n",
    "train_df['Spa'] = train_df['Spa'].fillna(train_df['Spa'].mean())#平均\n",
    "train_df['VRDeck'] = train_df['VRDeck'].fillna(train_df['VRDeck'].mean())#平均\n",
    "train_df['Name'] = train_df['Name'].fillna(\"somebody\")\n",
    "\n",
    "\n",
    "test_df['HomePlanet'] = test_df['HomePlanet'].fillna(test_df['HomePlanet'].mode()[0])#填众数\n",
    "test_df['CryoSleep'] = test_df['CryoSleep'].fillna(test_df['CryoSleep'].mode()[0])#填众数\n",
    "test_df['Cabin_Deck'] = test_df['Cabin_Deck'].fillna(test_df['Cabin_Deck'].mode()[0])#填众数\n",
    "test_df['Cabin_Number'] = test_df['Cabin_Number'].str[1].fillna(test_df['Cabin_Number'].mode()[0])#填众数\n",
    "test_df['Cabin_Side'] = test_df['Cabin_Side'].str[2].fillna(test_df['Cabin_Side'].mode()[0])#填众数\n",
    "test_df['Destination'] = test_df['Destination'].fillna(test_df['Destination'].mode()[0])\n",
    "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())#填中位数\n",
    "test_df['VIP'] = test_df['VIP'].fillna(test_df['VIP'].mode()[0])#填众数\n",
    "test_df['RoomService'] = test_df['RoomService'].fillna(test_df['RoomService'].mean())#平均\n",
    "test_df['FoodCourt'] = test_df['FoodCourt'].fillna(test_df['FoodCourt'].mean())#平均\n",
    "test_df['ShoppingMall'] = test_df['ShoppingMall'].fillna(test_df['ShoppingMall'].mean())#平均\n",
    "test_df['Spa'] = test_df['Spa'].fillna(test_df['Spa'].mean())#平均\n",
    "test_df['VRDeck'] = test_df['VRDeck'].fillna(test_df['VRDeck'].mean())#平均\n",
    "test_df['Name'] = test_df['Name'].fillna(\"somebody\")\n",
    "\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# 注：mode() 返回 Series，取 [0] 获取第一个众数\n",
    "columns_to_drop = ['Name','PassengerId','Cabin']\n",
    "# 剔除指定列\n",
    "train_df = train_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "test_df = test_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# 获取剩余的object类型列（需要进行独热编码的列）\n",
    "object_columns = train_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns=object_columns)\n",
    "# train_df = train_df[col for col in columns.map({True: 1, False: 0})]\n",
    "test_df = pd.get_dummies(test_df, columns=object_columns)\n",
    "\n",
    "for col in train_df.columns:\n",
    "    if col in test_df.columns and train_df[col].dtype == 'bool':\n",
    "        train_df[col] = train_df[col].map({True: 1, False: 0})\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# 转换布尔类型列为0和1\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].dtype == bool:\n",
    "        train_df[col] = train_df[col].astype(int)\n",
    "\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].dtype == bool:\n",
    "        test_df[col] = test_df[col].astype(int)\n",
    "\n",
    "feature_cols = [col for col in train_df.columns if col not in ['Transported']]\n",
    "\n",
    "# 对齐训练集和测试集的特征列\n",
    "common_features = list(set(feature_cols) & set(test_df.columns))\n",
    "common_features.sort()  # 保持一致的顺序\n",
    "\n",
    "\n",
    "X_train = train_df[common_features].to_numpy()  # 特征数据\n",
    "train_df_ = pd.read_csv('./data4_3/train.csv')  \n",
    "test_df_ = pd.read_csv('./data4_3/test.csv')#读取测试正确集\n",
    "y_train = train_df_['Transported'].to_numpy().ravel()  # 目标变量，转为一维数组\n",
    "for i in range(5):\n",
    "    print(f\"第{i}个样本的特征值: {X_train[i]}\\n {y_train[i]} \\n\")\n",
    "X_test = test_df[common_features].to_numpy()  # 特征数据\n",
    "y_test = test_df_['Transported'].to_numpy().ravel()  # 目标变量，转为一维数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cb532a",
   "metadata": {},
   "source": [
    "### 利用numpy实现逻辑回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0248fa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6931471805599453\n",
      "loss: 0.585861743332071\n",
      "loss: 0.5826594809928772\n",
      "loss: 0.5821111661414096\n",
      "loss: 0.5819468476055102\n",
      "loss: 0.5818415355830882\n",
      "loss: 0.5817456061436884\n",
      "loss: 0.5816512768976051\n",
      "loss: 0.581557314027715\n",
      "loss: 0.5814635209501362\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score# 用与计算准确率\n",
    "\n",
    "class LogisticRegression:\n",
    "    \"\"\"\n",
    "    逻辑回归模型\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, learning_rate=0.00001, num_iterations=10000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):# 训练模型\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self._sigmoid(linear_model)\n",
    "            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y))# 计算梯度\n",
    "            db = (1 / num_samples) * np.sum(y_predicted - y)\n",
    "            if _ % 1000 == 0:# 每1000次迭代打印loss值\n",
    "                print('loss:',self.cross_entropy_loss(y,y_predicted))\n",
    "\n",
    "            self.weights -= self.learning_rate * dw# 更新权重\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def _sigmoid(self, z):#  sigmoid函数\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def predict(self, X):# 预测函数\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self._sigmoid(linear_model)\n",
    "        y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return y_predicted_cls\n",
    "    \n",
    "    def cross_entropy_loss(self, y_true, y_pred):# 分类任务,使用交叉熵做损失函数\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "        return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
    "    \n",
    "\n",
    "    \n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy_score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy_score}\")\n",
    "\n",
    "# loss = model.cross_entropy_loss(y_test, y_pred)\n",
    "# print(f\"Cross Entropy Loss: {loss}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a4433c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59831474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
