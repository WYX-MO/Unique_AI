{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35cc7e3",
   "metadata": {},
   "source": [
    "#### 向ai询问了调用api的方法和rag的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b503f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import platform\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "DEEPSEEK_API_KEY = \"sk-2b814ccebc6e4d90b76ef40d2dd36f83\"\n",
    "DEEPSEEK_API_URL = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "class DeepSeekAPI:\n",
    "    def __init__(self, api_key=None, api_base=None, timeout=30):\n",
    "        self.api_key = api_key or os.getenv(\"DEEPSEEK_API_KEY\")\n",
    "        self.api_base = api_base or \"https://api.deepseek.com/v1\"\n",
    "        self.timeout = timeout\n",
    "        \n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"API密钥未设置\")\n",
    "        \n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\"\n",
    "        }\n",
    "    \n",
    "    def generate_text(self, messages, model=\"deepseek-chat\", max_tokens=1024, temperature=0.2,top_p=0.8):\n",
    "        endpoint = f\"{self.api_base}/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": messages,\n",
    "            \"max_tokens\": max_tokens,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(\n",
    "                endpoint,\n",
    "                headers=self.headers,\n",
    "                json=payload,\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            content = data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "            return {\"success\": True, \"content\": content, \"raw_data\": data}\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": f\"API调用失败: {str(e)}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc0437",
   "metadata": {},
   "source": [
    "### 普通的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce2dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": f\"简单回答用户问题,每个问题限制在20字内\"\n",
    "}\n",
    "user_prompt = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"帮我介绍⼀下华中科技⼤学优秀的学⽣社团 Unique Studio。我昨天没有写作业, 帮我想⼀个借⼝⾯对⽼师。我在实习期被辞退了, 依照法律, 我能够拿到补偿吗？张三说李四在说谎，李四说王五在说谎，王五说张三和李四都在说谎。请问到底谁在说谎？\"\n",
    "}\n",
    "\n",
    "api = DeepSeekAPI(api_key=DEEPSEEK_API_KEY)\n",
    "response = api.generate_text(messages=[system_prompt, user_prompt])\n",
    "\n",
    "if response[\"success\"]:\n",
    "    print(\"结果:\", response[\"content\"].strip())\n",
    "else:\n",
    "    print(f\"错误: {response.get('error', '未知错误')}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75571e19",
   "metadata": {},
   "source": [
    "## 使用RAG拓展DeepSeekAPI调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b215f0c6",
   "metadata": {},
   "source": [
    "## RAG增强下的deepseek回答（需要科学上网访问huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c02e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 配置环境变量\n",
    "os.environ[\"DEEPSEEK_API_KEY\"] = \"sk-2b814ccebc6e4d90b76ef40d2dd36f83\"\n",
    "\n",
    "# DeepSeek API调用函数\n",
    "def call_deepseek_api(prompt, model=\"deepseek-chat\"):\n",
    "    \"\"\"调用DeepSeek API生成回答\"\"\"\n",
    "    url = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {os.environ['DEEPSEEK_API_KEY']}\"\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": 0.2,\n",
    "        \"max_tokens\": 1024\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "    except Exception as e:\n",
    "        print(f\"调用DeepSeek API时出错: {e}\")\n",
    "        return None\n",
    "\n",
    "# 初始化向量数据库\n",
    "def init_vector_db(documents_dir=\"paper\"):\n",
    "    \"\"\"初始化向量数据库，加载知识库文档\"\"\"\n",
    "    # 加载文档\n",
    "    loader = DirectoryLoader(documents_dir, glob=\"*.txt\", loader_cls=TextLoader)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 分割文档\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \"。\", \"，\", \" \", \"\"]\n",
    "    )\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    \n",
    "    # 创建嵌入模型\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # 创建向量存储\n",
    "    vector_db = FAISS.from_documents(splits, embeddings)\n",
    "    \n",
    "    return vector_db\n",
    "\n",
    "# RAG增强的问答函数\n",
    "def rag_qa(vector_db, query):\n",
    "    \"\"\"结合RAG的问答功能\"\"\"\n",
    "    # 检索相关文档\n",
    "    retriever = vector_db.as_retriever(search_kwargs={\"k\": 3})  # 获取最相关的3个文档片段\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    # 构建带上下文的提示\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # 定义提示模板\n",
    "    prompt_template = \"\"\"你是一个问答专家，请基于以下提供的上下文信息来回答用户的问题。\n",
    "如果上下文信息不足以回答问题，请明确说明无法回答，不要编造信息。\n",
    "\n",
    "上下文信息:\n",
    "{context}\n",
    "\n",
    "用户的问题:\n",
    "{query}\n",
    "\n",
    "请给出你的回答:\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"query\"]\n",
    "    ).format(context=context, query=query)\n",
    "    \n",
    "    # 调用DeepSeek API获取回答\n",
    "    answer = call_deepseek_api(prompt)\n",
    "    \n",
    "    # 整理来源信息\n",
    "    sources = [{\"source\": doc.metadata[\"source\"], \"content\": doc.page_content[:100] + \"...\"} \n",
    "               for doc in relevant_docs]\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": sources\n",
    "    }\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 初始化向量数据库（首次运行会加载文档并创建向量库，后续可直接加载）\n",
    "    try:\n",
    "        # 尝试加载已存在的向量库\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=\"https://mirrors.aliyun.com/huggingface/hub/models--sentence-transformers--all-MiniLM-L6-v2/snapshots/all-MiniLM-L6-v2\")\n",
    "        vector_db = FAISS.load_local(\"faiss_index\", embeddings)\n",
    "        print(\"成功加载已存在的向量数据库\")\n",
    "    except:\n",
    "        # 不存在则创建新的向量库\n",
    "        print(\"正在初始化新的向量数据库...\")\n",
    "        vector_db = init_vector_db()\n",
    "        # 保存向量库供下次使用\n",
    "        vector_db.save_local(\"faiss_index\")\n",
    "        print(\"向量数据库初始化完成并保存\")\n",
    "    \n",
    "    # 示例查询\n",
    "    while True:\n",
    "        # query = input(\"\\n请输入你的问题（输入'q'退出）: \")\n",
    "        # if query.lower() == 'q':\n",
    "        #     break\n",
    "        \n",
    "        query = \"在2020年和2021年，由于疫情影响，全球健康预期寿命减少了多少年？在2019年，全球有多⼤⽐例的⼈⼝，其⾃付的医疗费⽤超过了家庭预算的10%？\"\n",
    "        result = rag_qa(vector_db, query)\n",
    "        \n",
    "        print(\"\\n回答:\")\n",
    "        print(result[\"answer\"])\n",
    "        \n",
    "        print(\"\\n参考来源:\")\n",
    "        for i, source in enumerate(result[\"sources\"], 1):\n",
    "            print(f\"{i}. 来源: {source['source']}\")\n",
    "            print(f\"   内容片段: {source['content']}\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124a18ca",
   "metadata": {},
   "source": [
    "![RAG增强下的deepseek回答](ans.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72938c19",
   "metadata": {},
   "source": [
    "## 普通调用下的deepseek回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a937ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": f\"回答用户问题\"\n",
    "}\n",
    "user_prompt = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"在2020年和2021年，由于疫情影响，全球健康预期寿命减少了多少年？在2019年，全球有多⼤⽐例的⼈⼝，其⾃付的医疗费⽤超过了家庭预算的10%？\"\n",
    "}\n",
    "\n",
    "api = DeepSeekAPI(api_key=DEEPSEEK_API_KEY)\n",
    "response = api.generate_text(messages=[system_prompt, user_prompt])\n",
    "\n",
    "if response[\"success\"]:\n",
    "    print(\"结果:\", response[\"content\"].strip())\n",
    "else:\n",
    "    print(f\"错误: {response.get('error', '未知错误')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d5d9cd",
   "metadata": {},
   "source": [
    "![普通](ans_1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14fa43b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
